Project for Practical Machine Learning Class
========================================================
__Overview__  
This is a submission for the course project for the "Practical Machine Learning"" course of taught by Professor Jeff Leeks at Johns Hopkins University as part of the Data Science specialization offered by Coursera.  

__Description of the Project__
A dataset was provided which collected data on the activity of six participants from accelerometers attached on the belt, forearm, arm and dumbell. The participant were asked to perform the excercise correctly and incorrectly in 5 different ways (referred as "classe"" column in the dataset). The aim of the project was to correctly predict the "classe" variable from the data provided. The dataset provided had 19622 rows and 160 columns (variables) including the "classe" variable. The aim was to develop a prediction function and predict the "classe" variable in the testing.csv file provided. The testing file also 20 rows and 160 columns. The "classe" value is not provided in the testing file but is instead replaced with a problem_id column. 

__Approach__ 

The entire training set file was loaded in R and reviewed visually. A quick visual review as well as the use of aggregation functions like summary and str in R showed that several columns had sparse or no data. The first step therefore to load the training and testing csv files and remove columns with sparse or null data and non-numerical variables.  
```{r, echo=FALSE, message=FALSE}
pml2<- read.csv("pml-testing.csv")
pml1<- read.csv("pml-training (1).csv")
print (str(pml1))

```
Dimensions of training data provided
```{r}
dim (pml1)
```
Dimensions after removing sparse data and non numerical variables. The column "X" was also removed as it seemed to indicate row numbers.
```{r, echo=FALSE, message=FALSE, results= FALSE}

k1 <- which(sapply(pml1, function(x){any(is.na(x))||any(x=="")}))
pml1a<- pml1[,-k1]
classes1a <- sapply(pml1a, class)
pml1b <- pml1a[,c(-1,-2,-6)]
dim(pml1b)
```

The new dataframe with reduced number of rows was then split into test and training sets in a 75 - 25 ratio respectively using the standard functions (createdataPartition) available in caret package.
```{r, echo=FALSE, message=FALSE, results=FALSE}
library(caret)
library(ggplot2)
inTrain = createDataPartition(y=pml1b$classe, p = 0.75, list=FALSE)
training = pml1b[inTrain,]
testing = pml1b[-inTrain,]
print ("Dimension for training and testing sets are:-")
print (dim(training)) ; print (dim(testing));
```

__Model Selection__  
The data was split in a 3:1 ratio of training set and testing set (cross validation) using the createDataPartition function in the caret package. The train function was used to identify a suitable model for the prediction. A trial and error approach was applied to achieve the final answer. The final prediction (classe) was a categorical variable with five possible choices. Models "glm"(general linear model), "rpart" (trees) and "gbm" (boosting with trees) were tried. Model "glm" did not yield any results while "rpart" was unable to catagorize the data into five categorial values (with no D values assigned at all). The "gbm" function was able to succesfully categorize data into five different categorical variables.

```{r, echo=FALSE, message=FALSE, results= FALSE}
library(gbm)
library(plyr)
library(parallel)
library(scatterplot3d)
modFit<- train(classe ~., data = training,method="gbm", verbose=FALSE)
```

__Model Performance__  

The model generated was used to predict "classe" values of the testing set. A 3-D plot of the predicted values versus actual values has been plotted below. As is evident, there are less than 20 mismatches (incorrect predictions) in over 4000 rows of predictions. The howllow circles represent the mismatches (incorrect ptdictions).

```{r, echo = FALSE, message = FALSE}
q1<- predict(modFit,testing)
q2<- predict(modFit, training)
scatterplot3d(q1,testing$classe, 1:length(q1), xlab = "Predicted Values", ylab = "Actual Values", zlab="Row Numbers", x.ticklabs=levels(q1), y.ticklabs=levels(testing$classe), z.ticklabs = NULL, highlight.3d=TRUE, angle=40, main = "Prediction Accuracy")
```

__Prediction Errors in Cross Validation__
The in sample error, i.e. the error in prediction of the training set was 
```{r, echo = FALSE, message = FALSE}
q2<- predict(modFit, training)
p2<- length(which(q2!=training$classe))
InSampleError <- round((p2/length(q2))*100, digits=2)
print (InSampleError)
cat("In Sample Error is", "  ", InSampleError,"%")
```

The out of sample error, i.e. the error in the prediction of the test set for cross validation is
```{r, echo = FALSE, message = FALSE}
q3<- predict(modFit, testing)
p3<- length(which(q3!=testing$classe))
OutOfSampleError <- round((p3/length(q3))*100, digits=2)
print (OutOfSampleError)
cat("Out of Sample Error is", "", OutOfSampleError,"%")
```

__Conclusions__

The succesful prediction model was identified using the caret package in R. A boosting method with trees (gbm) was eventually identified as most accurate after a series of trying few different models. All complete numeric columns were used for the prediction, except column "X" which served to represent row numbers. The accuracy for this model was over 99% (out of sample error 0.41%) and it succesfully predicted all 20 data points provided in the project submission section.



